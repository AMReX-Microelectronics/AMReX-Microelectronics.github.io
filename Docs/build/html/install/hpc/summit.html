<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Summit (OLCF) &mdash; MicroEleX 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            MicroEleX
          </a>
              <div class="version">
                1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">INSTALLATION</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ferrox.html">FerroX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">USAGE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../usage/how_to_run.html">Run WarpX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/domain_decomposition.html">Domain Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/parameters.html">Input Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/python.html">Python (PICMI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/examples.html">Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">DATA ANALYSIS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dataanalysis/formats.html">Output formats</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataanalysis/yt.html">yt-project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataanalysis/openpmdviewer.html">openPMD-viewer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataanalysis/openpmdapi.html">openPMD-api</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataanalysis/paraview.html">3D Visualization: ParaView</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataanalysis/visit.html">3D Visualization: VisIt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataanalysis/visualpic.html">VisualPIC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataanalysis/picviewer.html">PICViewer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataanalysis/reduced_diags.html">Reduced diagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataanalysis/workflows.html">Workflows</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">EPILOGUE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../acknowledgements.html">Funding and Acknowledgements</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MicroEleX</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Summit (OLCF)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/install/hpc/summit.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="summit-olcf">
<span id="building-summit"></span><h1>Summit (OLCF)<a class="headerlink" href="#summit-olcf" title="Link to this heading"></a></h1>
<p>The <a class="reference external" href="https://www.olcf.ornl.gov/summit/">Summit cluster</a> is located at OLCF.</p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<p>If you are new to this system, <strong>please see the following resources</strong>:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.olcf.ornl.gov/systems/summit_user_guide.html">Summit user guide</a></p></li>
<li><p>Batch system: <a class="reference external" href="https://docs.olcf.ornl.gov/systems/summit_user_guide.html#running-jobs">LSF</a></p></li>
<li><p><a class="reference external" href="https://jupyter.olcf.ornl.gov">Jupyter service</a></p></li>
<li><p><a class="reference external" href="https://docs.olcf.ornl.gov/data/index.html#data-storage-and-transfers">Production directories</a>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">$PROJWORK/$proj/</span></code>: shared with all members of a project, purged every 90 days, GPFS (recommended)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">$MEMBERWORK/$proj/</span></code>: single user, purged every 90 days, GPFS (usually smaller quota)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">$WORLDWORK/$proj/</span></code>: shared with all users, purged every 90 days, GPFS</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/ccs/$proj/</span></code>: another, non-GPFS, file system for software and smaller data.</p></li>
<li><p>Note that the <code class="docutils literal notranslate"><span class="pre">$HOME</span></code> directory is mounted as read-only on compute nodes.
That means you cannot run in your <code class="docutils literal notranslate"><span class="pre">$HOME</span></code>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Link to this heading"></a></h2>
<p>Use the following commands to download the WarpX source code and switch to the correct branch:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ECP-WarpX/WarpX.git<span class="w"> </span><span class="nv">$HOME</span>/src/warpx
</pre></div>
</div>
<p>We use the following modules and environments on the system (<code class="docutils literal notranslate"><span class="pre">$HOME/summit_warpx.profile</span></code>).</p>
<p>We recommend to store the above lines in a file, such as <code class="docutils literal notranslate"><span class="pre">$HOME/summit_warpx.profile</span></code>, and load it into your shell after a login:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span><span class="w"> </span><span class="nv">$HOME</span>/summit_warpx.profile
</pre></div>
</div>
<p>For PSATD+RZ simulations, you will need to build BLAS++ and LAPACK++:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># BLAS++ (for PSATD+RZ)</span>
git<span class="w"> </span>clone<span class="w"> </span>https://github.com/icl-utk-edu/blaspp.git<span class="w"> </span>src/blaspp
rm<span class="w"> </span>-rf<span class="w"> </span>src/blaspp-summit-build
cmake<span class="w"> </span>-S<span class="w"> </span>src/blaspp<span class="w"> </span>-B<span class="w"> </span>src/blaspp-summit-build<span class="w"> </span>-Duse_openmp<span class="o">=</span>OFF<span class="w"> </span>-Dgpu_backend<span class="o">=</span>cuda<span class="w"> </span>-DCMAKE_CXX_STANDARD<span class="o">=</span><span class="m">17</span><span class="w"> </span>-DCMAKE_INSTALL_PREFIX<span class="o">=</span><span class="nv">$HOME</span>/sw/summit/blaspp-master
cmake<span class="w"> </span>--build<span class="w"> </span>src/blaspp-summit-build<span class="w"> </span>--target<span class="w"> </span>install<span class="w"> </span>--parallel<span class="w"> </span><span class="m">10</span>

<span class="c1"># LAPACK++ (for PSATD+RZ)</span>
git<span class="w"> </span>clone<span class="w"> </span>https://github.com/icl-utk-edu/lapackpp.git<span class="w"> </span>src/lapackpp
rm<span class="w"> </span>-rf<span class="w"> </span>src/lapackpp-summit-build
cmake<span class="w"> </span>-S<span class="w"> </span>src/lapackpp<span class="w"> </span>-B<span class="w"> </span>src/lapackpp-summit-build<span class="w"> </span>-DCMAKE_CXX_STANDARD<span class="o">=</span><span class="m">17</span><span class="w"> </span>-Dbuild_tests<span class="o">=</span>OFF<span class="w"> </span>-DCMAKE_INSTALL_RPATH_USE_LINK_PATH<span class="o">=</span>ON<span class="w"> </span>-DCMAKE_INSTALL_PREFIX<span class="o">=</span><span class="nv">$HOME</span>/sw/summit/lapackpp-master
cmake<span class="w"> </span>--build<span class="w"> </span>src/lapackpp-summit-build<span class="w"> </span>--target<span class="w"> </span>install<span class="w"> </span>--parallel<span class="w"> </span><span class="m">10</span>
</pre></div>
</div>
<p>Optionally, download and install Python packages for <a class="reference internal" href="../../usage/python.html#usage-picmi"><span class="std std-ref">PICMI</span></a> or dynamic ensemble optimizations (<a class="reference internal" href="../../usage/workflows/libensemble.html#libensemble"><span class="std std-ref">libEnsemble</span></a>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span>--upgrade<span class="w"> </span>pip
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span>virtualenv
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>cache<span class="w"> </span>purge
rm<span class="w"> </span>-rf<span class="w"> </span><span class="nv">$HOME</span>/sw/venvs/warpx
python3<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span><span class="nv">$HOME</span>/sw/venvs/warpx
<span class="nb">source</span><span class="w"> </span><span class="nv">$HOME</span>/sw/venvs/warpx/bin/activate
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>wheel
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>cython
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>numpy
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pandas
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>scipy
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>mpi4py<span class="w"> </span>--no-binary<span class="w"> </span>mpi4py
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>openpmd-api
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span><span class="nv">matplotlib</span><span class="o">==</span><span class="m">3</span>.2.2<span class="w">  </span><span class="c1"># does not try to build freetype itself</span>
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>yt
<span class="c1"># WIP: issues with nlopt</span>
<span class="c1"># python3 -m pip install -r $HOME/src/warpx/Tools/LibEnsemble/requirements.txt</span>
</pre></div>
</div>
<p>Then, <code class="docutils literal notranslate"><span class="pre">cd</span></code> into the directory <code class="docutils literal notranslate"><span class="pre">$HOME/src/warpx</span></code> and use the following commands to compile:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span><span class="nv">$HOME</span>/src/warpx
rm<span class="w"> </span>-rf<span class="w"> </span>build

cmake<span class="w"> </span>-S<span class="w"> </span>.<span class="w"> </span>-B<span class="w"> </span>build<span class="w"> </span>-DWarpX_DIMS<span class="o">=</span><span class="m">3</span><span class="w"> </span>-DWarpX_COMPUTE<span class="o">=</span>CUDA
cmake<span class="w"> </span>--build<span class="w"> </span>build<span class="w"> </span>-j<span class="w"> </span><span class="m">6</span>
</pre></div>
</div>
<p>The general <a class="reference internal" href="../cmake.html#building-cmake"><span class="std std-ref">cmake compile-time options</span></a> apply as usual.</p>
<p>For a full PICMI install, follow the <a class="reference internal" href="../cmake.html#building-cmake-python"><span class="std std-ref">instructions for Python (PICMI) bindings</span></a>.
We only prefix it to request a node for the compilation (<code class="docutils literal notranslate"><span class="pre">runNode</span></code>), so we can compile faster:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># PICMI build</span>
<span class="nb">cd</span><span class="w"> </span><span class="nv">$HOME</span>/src/warpx

<span class="c1"># install or update dependencies</span>
python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt

<span class="c1"># compile parallel PICMI interfaces in 3D, 2D, 1D and RZ</span>
runNode<span class="w"> </span><span class="nv">WARPX_MPI</span><span class="o">=</span>ON<span class="w"> </span><span class="nv">WARPX_COMPUTE</span><span class="o">=</span>CUDA<span class="w"> </span><span class="nv">WARPX_PSATD</span><span class="o">=</span>ON<span class="w"> </span><span class="nv">BUILD_PARALLEL</span><span class="o">=</span><span class="m">32</span><span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--force-reinstall<span class="w"> </span>--no-deps<span class="w"> </span>-v<span class="w"> </span>.
</pre></div>
</div>
<p>Or, if you are <em>developing</em>, do a quick PICMI install of a <em>single geometry</em> (see: <a class="reference internal" href="../cmake.html#building-cmake-options"><span class="std std-ref">WarpX_DIMS</span></a>) using:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># find dependencies &amp; configure</span>
cmake<span class="w"> </span>-S<span class="w"> </span>.<span class="w"> </span>-B<span class="w"> </span>build<span class="w"> </span>-DWarpX_COMPUTE<span class="o">=</span>CUDA<span class="w"> </span>-DWarpX_PSATD<span class="o">=</span>ON<span class="w"> </span>-DWarpX_LIB<span class="o">=</span>ON<span class="w"> </span>-DWarpX_DIMS<span class="o">=</span>RZ

<span class="c1"># build and then call &quot;python3 -m pip install ...&quot;</span>
cmake<span class="w"> </span>--build<span class="w"> </span>build<span class="w"> </span>--target<span class="w"> </span>pip_install<span class="w"> </span>-j<span class="w"> </span><span class="m">6</span>
</pre></div>
</div>
</section>
<section id="running">
<span id="running-cpp-summit"></span><h2>Running<a class="headerlink" href="#running" title="Link to this heading"></a></h2>
<section id="v100-gpus-16gb">
<span id="running-cpp-summit-v100-gpus"></span><h3>V100 GPUs (16GB)<a class="headerlink" href="#v100-gpus-16gb" title="Link to this heading"></a></h3>
<p>The batch script below can be used to run a WarpX simulation on 2 nodes on
the supercomputer Summit at OLCF. Replace descriptions between chevrons <code class="docutils literal notranslate"><span class="pre">&lt;&gt;</span></code>
by relevant values, for instance <code class="docutils literal notranslate"><span class="pre">&lt;input</span> <span class="pre">file&gt;</span></code> could be
<code class="docutils literal notranslate"><span class="pre">plasma_mirror_inputs</span></code>.
Note that WarpX runs with one MPI rank per GPU and there are 6 GPUs per node:</p>
<p>To run a simulation, copy the lines above to a file <code class="docutils literal notranslate"><span class="pre">summit_v100.bsub</span></code> and
run</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">bsub</span><span class="w"> </span><span class="n">summit_v100</span><span class="p">.</span><span class="n">bsub</span>
</pre></div>
</div>
<p>to submit the job.</p>
<p>For a 3D simulation with a few (1-4) particles per cell using FDTD Maxwell
solver on Summit for a well load-balanced problem (in our case laser
wakefield acceleration simulation in a boosted frame in the quasi-linear
regime), the following set of parameters provided good performance:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">amr.max_grid_size=256</span></code> and <code class="docutils literal notranslate"><span class="pre">amr.blocking_factor=128</span></code>.</p></li>
<li><p><strong>One MPI rank per GPU</strong> (e.g., 6 MPI ranks for the 6 GPUs on each Summit
node)</p></li>
<li><p><strong>Two `128x128x128` grids per GPU</strong>, or <strong>one `128x128x256` grid per GPU</strong>.</p></li>
</ul>
<p>A batch script with more options regarding profiling on Summit can be found at
<code class="xref download docutils literal notranslate"><span class="pre">Summit</span> <span class="pre">batch</span> <span class="pre">script</span></code></p>
</section>
<section id="power9-cpus">
<span id="running-cpp-summit-power9-cpus"></span><h3>Power9 CPUs<a class="headerlink" href="#power9-cpus" title="Link to this heading"></a></h3>
<p>Similar to above, the batch script below can be used to run a WarpX simulation on
1 node on the supercomputer Summit at OLCF, on Power9 CPUs (i.e., the GPUs are
ignored).</p>
<p>For a 3D simulation with a few (1-4) particles per cell using FDTD Maxwell
solver on Summit for a well load-balanced problem, the following set of
parameters provided good performance:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">amr.max_grid_size=64</span></code> and <code class="docutils literal notranslate"><span class="pre">amr.blocking_factor=64</span></code></p></li>
<li><p><strong>Two MPI ranks per node</strong> (i.e. 2 resource sets per node; equivalently, 1
resource set per socket)</p></li>
<li><p><strong>21 physical CPU cores per MPI rank</strong></p></li>
<li><p><strong>21 OpenMP threads per MPI rank</strong> (i.e. 1 OpenMP thread per physical core)</p></li>
<li><p><strong>SMT 1 (Simultaneous Multithreading level 1)</strong></p></li>
<li><p><strong>Sixteen `64x64x64` grids per MPI rank</strong> (with default tiling in WarpX, this
results in ~49 tiles per OpenMP thread)</p></li>
</ul>
</section>
</section>
<section id="i-o-performance-tuning">
<span id="building-summit-io-performance"></span><h2>I/O Performance Tuning<a class="headerlink" href="#i-o-performance-tuning" title="Link to this heading"></a></h2>
<section id="gpfs-large-block-i-o">
<span id="building-summit-large-blocks"></span><h3>GPFS Large Block I/O<a class="headerlink" href="#gpfs-large-block-i-o" title="Link to this heading"></a></h3>
<p>Setting <code class="docutils literal notranslate"><span class="pre">IBM_largeblock_io</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code> disables data shipping, saving overhead when writing/reading large contiguous I/O chunks.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">IBM_largeblock_io</span><span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
</section>
<section id="romio-mpi-io-hints">
<span id="building-summit-romio-hints"></span><h3>ROMIO MPI-IO Hints<a class="headerlink" href="#romio-mpi-io-hints" title="Link to this heading"></a></h3>
<p>You might notice some parallel HDF5 performance improvements on Summit by setting the appropriate ROMIO hints for MPI-IO operations.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">OMPI_MCA_io</span><span class="o">=</span>romio321
<span class="nb">export</span><span class="w"> </span><span class="nv">ROMIO_HINTS</span><span class="o">=</span>./romio-hints
</pre></div>
</div>
<p>You can generate the <code class="docutils literal notranslate"><span class="pre">romio-hints</span></code> by issuing the following command. Remember to change the number of <code class="docutils literal notranslate"><span class="pre">cb_nodes</span></code> to match the number of compute nodes you are using (example here: <code class="docutils literal notranslate"><span class="pre">64</span></code>).</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat<span class="w"> </span>&gt;<span class="w"> </span>romio-hints<span class="w"> </span><span class="s">&lt;&lt; EOL</span>
<span class="s">romio_cb_write enable</span>
<span class="s">romio_ds_write enable</span>
<span class="s">cb_buffer_size 16777216</span>
<span class="s">cb_nodes 64</span>
<span class="s">EOL</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">romio-hints</span></code> file contains pairs of key-value hints to enable and tune collective
buffering of MPI-IO operations. As Summit’s Alpine file system uses a 16MB block size,
you should set the collective buffer size to 16GB and tune the number of aggregators
(<code class="docutils literal notranslate"><span class="pre">cb_nodes</span></code>) to the number of compute nodes you are using, i.e., one aggregator per node.</p>
<p>Further details are available at <a class="reference external" href="https://docs.olcf.ornl.gov/systems/summit_user_guide.html#slow-performance-using-parallel-hdf5-resolved-march-12-2019">Summit’s documentation page</a>.</p>
</section>
</section>
<section id="known-system-issues">
<span id="building-summit-issues"></span><h2>Known System Issues<a class="headerlink" href="#known-system-issues" title="Link to this heading"></a></h2>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Sep 16th, 2021 (OLCFHELP-3685):
The <strong>Jupyter</strong> service cannot open HDF5 files without hanging, due to a filesystem mounting problem.</p>
<p><a class="reference external" href="https://github.com/openPMD/openPMD-api/pull/1106">Please apply this work-around</a> in a Jupyter cell before opening any HDF5 files for read:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;HDF5_USE_FILE_LOCKING&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;FALSE&quot;</span>
</pre></div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Aug 27th, 2021 (OLCFHELP-3442):
Created simulation files and directories are no longer accessible by your team members, even if you create them on <code class="docutils literal notranslate"><span class="pre">$PROJWORK</span></code>.
Setting the proper “user mask” (<code class="docutils literal notranslate"><span class="pre">umask</span></code>) does not yet work to fix this.</p>
<p>Please run those commands <em>after</em> running a simulation to fix this.
You can also append this to the end of your job scripts <em>after</em> the <code class="docutils literal notranslate"><span class="pre">jsrun</span></code> line:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># cd your-simulation-directory</span>
find<span class="w"> </span>.<span class="w"> </span>-type<span class="w"> </span>d<span class="w"> </span>-exec<span class="w"> </span>chmod<span class="w"> </span>g+rwx<span class="w"> </span><span class="o">{}</span><span class="w"> </span><span class="se">\;</span>
find<span class="w"> </span>.<span class="w"> </span>-type<span class="w"> </span>f<span class="w"> </span>-exec<span class="w"> </span>chmod<span class="w"> </span>g+rw<span class="w"> </span><span class="o">{}</span><span class="w"> </span><span class="se">\;</span>
</pre></div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Sep 3rd, 2021 (OLCFHELP-3545):
The implementation of barriers in IBM’s MPI fork is broken and leads to crashes at scale.
This is seen with runs using 200 nodes and above.</p>
<p>Our batch script templates above <a class="reference external" href="https://github.com/ECP-WarpX/WarpX/pull/2283">apply this work-around</a> <em>before</em> the call to <code class="docutils literal notranslate"><span class="pre">jsrun</span></code>, which avoids the broken routines from IBM and trades them for an OpenMPI implementation of collectives:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">OMPI_MCA_coll_ibm_skip_barrier</span><span class="o">=</span><span class="nb">true</span>
</pre></div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Sep 3rd, 2021 (OLCFHELP-3319):
If you are an active developer and compile middleware libraries (e.g., ADIOS2) yourself that use MPI and/or infiniband, be aware of <code class="docutils literal notranslate"><span class="pre">libfabric</span></code>: IBM forks the open source version of this library and ships a patched version.</p>
<p>Avoid conflicts with mainline versions of this library in MPI that lead to crashes at runtime by loading alongside the system MPI module:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>module<span class="w"> </span>load<span class="w"> </span>libfabric/1.12.1-sysrdma
</pre></div>
</div>
<p>For instance, if you compile large software stacks with Spack, make sure to register <code class="docutils literal notranslate"><span class="pre">libfabric</span></code> with that exact version as an external module.</p>
<p>If you load the documented ADIOS2 module above, this problem does not affect you, since the correct <code class="docutils literal notranslate"><span class="pre">libfabric</span></code> version is chosen for this one.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Related to the above issue, the fabric selection in ADIOS2 was designed for libfabric 1.6.
With newer versions of libfabric, a workaround is needed to guide the selection of a functional fabric for RDMA support.
Details are discussed in <a class="reference external" href="https://github.com/ornladios/ADIOS2/issues/2887">ADIOS2 issue #2887</a>.</p>
<p>The following environment variables can be set as work-arounds, when working with ADIOS2 SST:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">FABRIC_IFACE</span><span class="o">=</span>mlx5_0<span class="w">   </span><span class="c1"># ADIOS SST: select interface (1 NIC on Summit)</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">FI_OFI_RXM_USE_SRX</span><span class="o">=</span><span class="m">1</span><span class="w">  </span><span class="c1"># libfabric: use shared receive context from MSG provider</span>
</pre></div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Oct 12th, 2021 (OLCFHELP-4242):
There is currently a problem with the pre-installed Jupyter extensions, which can lead to connection splits at long running analysis sessions.</p>
<p>Work-around this issue by running in a single Jupyter cell, before starting analysis:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!jupyter<span class="w"> </span>serverextension<span class="w"> </span><span class="nb">enable</span><span class="w"> </span>--py<span class="w"> </span>--sys-prefix<span class="w"> </span>dask_labextension
</pre></div>
</div>
</div>
</section>
<section id="post-processing">
<span id="post-processing-summit"></span><h2>Post-Processing<a class="headerlink" href="#post-processing" title="Link to this heading"></a></h2>
<p>For post-processing, most users use Python via OLCFs’s <a class="reference external" href="https://jupyter.olcf.ornl.gov">Jupyter service</a> (<a class="reference external" href="https://docs.olcf.ornl.gov/services_and_applications/jupyter/index.html">Docs</a>).</p>
<p>We usually just install our software on-the-fly on Summit.
When starting up a post-processing session, run this in your first cells:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The following software packages are installed only into a temporary directory.</p>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># work-around for OLCFHELP-4242</span>
!jupyter<span class="w"> </span>serverextension<span class="w"> </span><span class="nb">enable</span><span class="w"> </span>--py<span class="w"> </span>--sys-prefix<span class="w"> </span>dask_labextension

<span class="c1"># next Jupyter cell: the software you want</span>
!mamba<span class="w"> </span>install<span class="w"> </span>--quiet<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>-y<span class="w"> </span>openpmd-api<span class="w"> </span>openpmd-viewer<span class="w"> </span>ipympl<span class="w"> </span>ipywidgets<span class="w"> </span>fast-histogram<span class="w"> </span>yt

<span class="c1"># restart notebook</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017-2024, MicroEleX collaboration.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>